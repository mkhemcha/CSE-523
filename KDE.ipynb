{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.94894079304726\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "from autocorrect import spell\n",
    "from numpy.linalg import inv\n",
    "from scipy.spatial import KDTree\n",
    "from nltk import edit_distance\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "def checkeditDistance(word1,dict):\n",
    "    for word2 in dict:\n",
    "        if(edit_distance(word1,word2) <= 3):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def wordBreak(s, dict):\n",
    "    sLen = len(s)\n",
    "    possible = [False for i in range(sLen + 1)]\n",
    "    possible[0] = True\n",
    "\n",
    "    for i in range(sLen):\n",
    "        for j in range(i + 1):\n",
    "            if possible[j] and s[j:i + 1] in dict:\n",
    "                possible[i + 1] = True\n",
    "                break\n",
    "\n",
    "    return possible[sLen]\n",
    "    \n",
    "    \n",
    "def computeadaptivekde(place_location,word_loc_dict):\n",
    "    temp=getxandy(place_location)\n",
    "    lp1=float(temp[0])\n",
    "    lp2=float(temp[1])\n",
    "    rankings=dict()\n",
    "    for key,value in word_loc_dict.items():\n",
    "        word=key\n",
    "        word_location=[]\n",
    "        for location in value:\n",
    "            loc=getxandy(location)\n",
    "            x=float(loc[0])\n",
    "            y=float(loc[1])\n",
    "            add=[x,y]\n",
    "            word_location.append(add)\n",
    "        if(len(word_location) <= 200 and len(word_location) > 0):\n",
    "            h=findKnearestneighbour(temp,word_location)\n",
    "            score=compute(h,value,lp1,lp2)\n",
    "            rankings[word]=score\n",
    "    top_words=[]\n",
    "    temp=sorted(rankings.items(), key=lambda x:x[1])\n",
    "#     print(temp)\n",
    "    i=0\n",
    "    for key,value in temp:\n",
    "        top_words.append(key)\n",
    "        i+=1\n",
    "        if(i==10):\n",
    "            break\n",
    "    return top_words\n",
    "    \n",
    "    \n",
    "    \n",
    "def findKnearestneighbour(placelocation,location_list):\n",
    "    point=[float(placelocation[0]),float(placelocation[1])]\n",
    "    if (len(location_list) <= 200):\n",
    "        tree = KDTree(location_list)\n",
    "        distances, ndx = tree.query([point], k=5)\n",
    "        distances[np.isposinf(distances)] = -9999\n",
    "        p=np.where(distances==-9999.0)\n",
    "        temp=distances.tolist()\n",
    "        if len(p[1])==0:\n",
    "            return temp[0][-1]\n",
    "        else:\n",
    "            return temp[0][p[1][0]-1]    \n",
    "\n",
    "def computekdefixed(place_location,word_loc_dict):\n",
    "    temp=getxandy(place_location)\n",
    "    lp1=float(temp[0])\n",
    "    lp2=float(temp[1])\n",
    "    rankings=dict()\n",
    "    for key,value in word_loc_dict.items():\n",
    "        word=key\n",
    "        score=compute(10,value,lp1,lp2)\n",
    "        rankings[word]=score\n",
    "    top_words=[]\n",
    "    temp=sorted(rankings.items(), key=lambda x:x[1],reverse=True)\n",
    "    i=0\n",
    "    for key,value in temp:\n",
    "        top_words.append(key)\n",
    "        i+=1\n",
    "        if(i==20):\n",
    "            break\n",
    "    return top_words\n",
    "            \n",
    "#KDE fixed formula for a particular belonging to particular place\n",
    "def compute(h,locationlist,lp1,lp2):\n",
    "    C_h=np.matrix([[float(h),float(0)],[float(0),float(h)]])\n",
    "    C_h_inv=inv(C_h)\n",
    "    val=[]\n",
    "    for location in locationlist:\n",
    "        temp=getxandy(location)\n",
    "        l1w=float(temp[0])\n",
    "        l2w=float(temp[1])\n",
    "        dx=l1w - lp1\n",
    "        dy=l2w - lp2\n",
    "        loc_mat=np.matrix([[dx],[dy]])\n",
    "        loc_mat_transpose=np.transpose(loc_mat)\n",
    "        inner=(-1/2)*(np.matmul(np.matmul(loc_mat_transpose,C_h_inv),loc_mat))\n",
    "        guassian=(1/(2*math.pi*h))*(math.exp(inner))\n",
    "        val.append(guassian)\n",
    "    return ((1/len(locationlist)) * sum(val))\n",
    "    \n",
    "def getxandy(location):\n",
    "    i=0;\n",
    "    string=location[location.index('(')+1:location.index(')')]\n",
    "    return string.split(\" \")\n",
    "\n",
    "\n",
    "def computeaccuracy(top_words):\n",
    "    counter=0;\n",
    "    for key,value in top_words.items():\n",
    "        string_array=key.split();\n",
    "        dict=[word.lower() for word in string_array]\n",
    "        for word in value:\n",
    "            if wordBreak(word.lower(),dict):\n",
    "                counter+=1\n",
    "                break\n",
    "    print((counter/len(top_words))*100)\n",
    "            \n",
    "\n",
    "\n",
    "input_data=pd.read_csv('final_data.csv')\n",
    "del input_data['Unnamed: 0']\n",
    "input_data.head()\n",
    "dictionary=dict()\n",
    "\n",
    "# develop L vector\n",
    "place_word=dict()\n",
    "place_loc=dict()\n",
    "groupbyplaceid=input_data.groupby('PlaceId')\n",
    "for name,group in groupbyplaceid:\n",
    "    word_loc=dict()\n",
    "    for index,row in group.iterrows():\n",
    "        placelocation=row['Placelocation']\n",
    "        placename=row['Name']\n",
    "        placedid=row['PlaceId']\n",
    "        twitterlocation=row['Twitterlocation']\n",
    "        tokens=list(row['content'])\n",
    "        length=len(tokens)\n",
    "        i=0\n",
    "        token_list=[]\n",
    "        while i < length:\n",
    "            str=\"\"\n",
    "            if tokens[i] == '\\'':\n",
    "                i+=1\n",
    "                while(i < length and tokens[i] != '\\''):\n",
    "                    str=str+tokens[i]\n",
    "                    i+=1\n",
    "                token_list.append(str)\n",
    "            i+=1\n",
    "        #word list for a particular twitter\n",
    "        #multiple mentions of word in a single tweet count only once i.e. set(token_list)\n",
    "        string_array=placename.split()\n",
    "        set_of_tokens=set(token_list)\n",
    "        set_of_tokens_deepcopy=copy.deepcopy(set_of_tokens)\n",
    "        for word in set_of_tokens:\n",
    "            if wordBreak(word.lower(),string_array):\n",
    "                set_of_tokens_deepcopy.remove(word)\n",
    "                set_of_tokens_deepcopy.add(''.join(string_array))\n",
    "            elif checkeditDistance(word,string_array):\n",
    "                set_of_tokens_deepcopy.remove(word)\n",
    "                set_of_tokens_deepcopy.add(''.join(string_array))\n",
    "                \n",
    "        for word in set_of_tokens_deepcopy:\n",
    "            if \"http\" not in word and len(word)>=3:\n",
    "                #Standardizing words: Sometimes words are not in proper formats. For example: “I looooveee you” should be “I love you”. \n",
    "#               Simple rules and regular expressions can help solve these cases.\n",
    "                word=''.join(''.join(s)[:2] for _, s in itertools.groupby(word))\n",
    "                word_loc.setdefault(word.lower(), []).append(twitterlocation)\n",
    "    place_word[placelocation]=word_loc\n",
    "#     plac\n",
    "    place_loc[placelocation]=placename\n",
    "\n",
    "\n",
    "# print(place_word['POINT (1.296346739687204 52.6285572)'])\n",
    "top_words=dict()\n",
    "\n",
    "# top_5=computeadaptivekde(\"POINT (1.296346739687204 52.6285572)\",place_word['POINT (1.296346739687204 52.6285572)'])\n",
    "\n",
    "# print(top_5)\n",
    "\n",
    "# print(top_5)\n",
    "# for key,value in place_word.items():\n",
    "#     top_10=computekdefixed(key,value)\n",
    "#     top_words[place_loc[key]]=top_10\n",
    "# computeaccuracy(top_words)\n",
    "\n",
    "top_words1=dict()\n",
    "for key,value in place_word.items():\n",
    "    top_10=computeadaptivekde(key,value)\n",
    "    top_words1[place_loc[key]]=top_10\n",
    "\n",
    "# print(top_words1)\n",
    "computeaccuracy(top_words1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
